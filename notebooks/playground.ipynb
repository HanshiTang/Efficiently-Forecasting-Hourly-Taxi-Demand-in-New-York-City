{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add new column ##\n",
    "df_renamed = df_all.withColumnRenamed(\"RatecodeID\", \"Rate_codeID\") \n",
    "df_renamed.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped = df_all.drop(\"passenger_count_plus_10\")\n",
    "df_dropped.show(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.groupBy(\"VendorID\").agg({\"passenger_count\": \"avg\", \"extra\": \"max\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sampling Data\n",
    "SAMPLE_SIZE = 0.01\n",
    "df = df_all.sample(SAMPLE_SIZE, seed = 20020223).toPandas() \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019_1.printSchema() \n",
    "print(f\"数据总量: {df_2019_1.count()}\") \n",
    "df_2019_1.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## missing data \n",
    "df_2019_1 = df_2019_1.dropna()\n",
    "df_2019_1 = df_2019_1.fillna({'passenger_count': 1, 'trip_distance': 0.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datatype conversion\n",
    "df_2019_1 = df_2019_1.withColumn(\"passenger_count\", col(\"passenger_count\").cast(\"integer\"))\n",
    "df_2019_1 = df_2019_1.withColumn(\"tpep_pickup_datetime\", col(\"tpep_pickup_datetime\")) \n",
    "df_2019_1 = df_2019_1.withColumn(\"tpep_dropoff_datetime\", col(\"tpep_dropoff_datetime\"))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicate data\n",
    "df_2019_1 = df_2019_1.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anomaly data\n",
    "trip_distance_min = 0\n",
    "trip_distance_max = 100\n",
    "df_2019_1 = df_2019_1.filter((df_2019_1[\"trip_distance\"] > trip_distance_min) & (df_2019_1[\"trip_distance\"] > trip_distance_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardization\n",
    "from pyspark.ml.feature import StandardScaler, VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=[\"trip_distance\", \"trip_duration\"], outputCol= \"features\")\n",
    "df_features = assembler.transform(df_2019_1)\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\") \n",
    "scaler_model = scaler.fit(df_features)\n",
    "df_scaled = scaler_model.transform(df_features)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
