{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sbs\n",
    "import geopandas as gpd\n",
    "import folium \n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, OneHotEncoder, StringIndexer\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a spark session with increased memory allocation\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"ADS Project1\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.driver.memory\", \"8g\")  # Set the driver memory to 8GB\n",
    "    .config(\"spark.executor.memory\", \"8g\")  # Set the executor memory to 8GB\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data\n",
    "spark.conf.set(\"spark.sql.parquet.compression.codec\",\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = spark.read.parquet(\"../data/curated/tlc_data/first_cleaned.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DOLocationID', 'PULocationID', 'pickup_date', 'pickup_hour', 'dropoff_date', 'dropoff_hour', 'VendorID', 'passenger_count', 'trip_distance', 'trip_duration', 'RatecodeID', 'store_and_fwd_flag', 'PUBorough', 'DOBorough', 'payment_type', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'total_amount', 'congestion_surcharge', 'ehail_fee', 'hourly_trip_count', 'daily_trip_count', 'CIG', 'WND', 'VIS', 'TMP', 'DEW', 'SLP', 'Number of Events']\n"
     ]
    }
   ],
   "source": [
    "# get features\n",
    "features = df.columns\n",
    "# print the features\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training (60%), validation (20%), and test (20%)\n",
    "train_df, validation_df, test_df = df.randomSplit([0.6, 0.2, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example categorical columns\n",
    "categorical_columns = ['categorical_column1', 'categorical_column2']\n",
    "\n",
    "# Indexers: Converting categorical string columns to numeric indices\n",
    "indexers = [StringIndexer(inputCol=column, outputCol=column + \"_index\") for column in categorical_columns]\n",
    "\n",
    "# Encoders: Converting numeric indices to one-hot encoded vectors\n",
    "encoders = [OneHotEncoder(inputCol=column + \"_index\", outputCol=column + \"_ohe\") for column in categorical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble the feature vector\n",
    "assembler = VectorAssembler(inputCols=[<your_selected_columns>], outputCol=\"features\")\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n",
    "\n",
    "# Linear Regression\n",
    "lr = LinearRegression(featuresCol=\"scaled_features\", labelCol=\"hourly_trip_count\")\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline(stages=indexers + encoders + [assembler, scaler, lr])\n",
    "\n",
    "# Fit the model on the training set\n",
    "model = pipeline.fit(train_df)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "validation_predictions = model.transform(validation_df)\n",
    "evaluator = RegressionEvaluator(labelCol=\"hourly_trip_count\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "validation_rmse = evaluator.evaluate(validation_predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE) on validation data = {validation_rmse}\")\n",
    "\n",
    "# If satisfied with validation performance, evaluate on the test set\n",
    "test_predictions = model.transform(test_df)\n",
    "test_rmse = evaluator.evaluate(test_predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE) on test data = {test_rmse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
