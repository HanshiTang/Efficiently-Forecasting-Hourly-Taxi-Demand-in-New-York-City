{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sbs\n",
    "import geopandas as gpd\n",
    "import folium \n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, OneHotEncoder, StringIndexer\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a spark session with increased memory allocation\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"ADS Project1\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.driver.memory\", \"8g\")  # Set the driver memory to 8GB\n",
    "    .config(\"spark.executor.memory\", \"8g\")  # Set the executor memory to 8GB\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data\n",
    "spark.conf.set(\"spark.sql.parquet.compression.codec\",\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = spark.read.parquet(\"../data/curated/tlc_data/first_cleaned.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing the categorical columns\n",
    "vendor_indexer = StringIndexer(inputCol=\"VendorID\", outputCol=\"VendorID_index\")\n",
    "ratecode_indexer = StringIndexer(inputCol=\"RatecodeID\", outputCol=\"RatecodeID_index\")\n",
    "payment_type_indexer = StringIndexer(inputCol=\"payment_type\", outputCol=\"payment_type_index\")\n",
    "\n",
    "# OneHotEncoding the indexed columns\n",
    "vendor_encoder = OneHotEncoder(inputCol=\"VendorID_index\", outputCol=\"VendorID_vec\")\n",
    "ratecode_encoder = OneHotEncoder(inputCol=\"RatecodeID_index\", outputCol=\"RatecodeID_vec\")\n",
    "payment_type_encoder = OneHotEncoder(inputCol=\"payment_type_index\", outputCol=\"payment_type_vec\")\n",
    "\n",
    "# Creating a pipeline to chain indexers and encoders\n",
    "pipeline = Pipeline(stages=[vendor_indexer, ratecode_indexer, payment_type_indexer,\n",
    "                            vendor_encoder, ratecode_encoder, payment_type_encoder])\n",
    "\n",
    "# Fit the pipeline and transform the data\n",
    "model = pipeline.fit(combined)\n",
    "encoded_df = model.transform(combined)\n",
    "\n",
    "# Drop the original columns after encoding\n",
    "encoded_df = encoded_df.drop(\"VendorID\", \"RatecodeID\", \"payment_type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assembling the feature vector\n",
    "assembler = VectorAssembler(inputCols=[<your_selected_columns>], outputCol=\"features\")\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n",
    "\n",
    "# Linear Regression\n",
    "lr = LinearRegression(featuresCol=\"scaled_features\", labelCol=\"hourly_trip_count\")\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline(stages=indexers + encoders + [assembler, scaler, lr])\n",
    "\n",
    "# Fit the model\n",
    "model = pipeline.fit(train_df)\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = model.transform(test_df)\n",
    "evaluator = RegressionEvaluator(labelCol=\"hourly_trip_count\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Root Mean Squared Error (RMSE) on test data = {rmse}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
