{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Assuming 'df' is your PySpark DataFrame and 'feature_column' is the column you want to standardize\n",
    "\n",
    "# Step 1: Assemble the feature column into a Vector\n",
    "assembler = VectorAssembler(inputCols=['feature_column'], outputCol='feature_vector')\n",
    "df_vector = assembler.transform(df)\n",
    "\n",
    "# Step 2: Apply StandardScaler to the vectorized column\n",
    "scaler = StandardScaler(inputCol='feature_vector', outputCol='scaled_feature', withMean=True, withStd=True)\n",
    "scaler_model = scaler.fit(df_vector)\n",
    "df_scaled = scaler_model.transform(df_vector)\n",
    "\n",
    "# The 'scaled_feature' column now contains the standardized values\n",
    "# If you want to extract the scaled feature back to a column:\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "df_scaled = df_scaled.withColumn('scaled_feature_column', vector_to_array('scaled_feature')[0])\n",
    "\n",
    "# Select the original and the standardized columns for viewing\n",
    "df_scaled.select('feature_column', 'scaled_feature_column').show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Indexing the categorical columns\n",
    "vendor_indexer = StringIndexer(inputCol=\"VendorID\", outputCol=\"VendorID_index\")\n",
    "ratecode_indexer = StringIndexer(inputCol=\"RatecodeID\", outputCol=\"RatecodeID_index\")\n",
    "payment_type_indexer = StringIndexer(inputCol=\"payment_type\", outputCol=\"payment_type_index\")\n",
    "\n",
    "# OneHotEncoding the indexed columns\n",
    "vendor_encoder = OneHotEncoder(inputCol=\"VendorID_index\", outputCol=\"VendorID_vec\")\n",
    "ratecode_encoder = OneHotEncoder(inputCol=\"RatecodeID_index\", outputCol=\"RatecodeID_vec\")\n",
    "payment_type_encoder = OneHotEncoder(inputCol=\"payment_type_index\", outputCol=\"payment_type_vec\")\n",
    "\n",
    "# Creating a pipeline to chain indexers and encoders\n",
    "pipeline = Pipeline(stages=[vendor_indexer, ratecode_indexer, payment_type_indexer,\n",
    "                            vendor_encoder, ratecode_encoder, payment_type_encoder])\n",
    "\n",
    "# Fit the pipeline and transform the data\n",
    "model = pipeline.fit(combined)\n",
    "encoded_df = model.transform(combined)\n",
    "\n",
    "# Drop the original columns after encoding\n",
    "encoded_df = encoded_df.drop(\"VendorID\", \"RatecodeID\", \"payment_type\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
