{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sbs\n",
    "import geopandas as gpd\n",
    "import folium "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/30 01:23:53 WARN Utils: Your hostname, Hanshis-Laptop.local resolves to a loopback address: 127.0.0.1; using 100.94.176.147 instead (on interface en0)\n",
      "24/08/30 01:23:53 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/08/30 01:23:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a spark session with increased memory allocation\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"ADS Project1\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.driver.memory\", \"8g\")  # Set the driver memory to 8GB\n",
    "    .config(\"spark.executor.memory\", \"8g\")  # Set the executor memory to 8GB\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data from preprocessed tlc data\n",
    "tdf = spark.read.parquet(\"../data/raw/tlc_df.parquet\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the preprocessed weather data\n",
    "wdf = spark.read.csv(\"../data/raw/NYC_weather_raw.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the preprocessed event data\n",
    "edf = spark.read.parquet(\"../data/raw/NYC_Permitted_Event_Information_Historical.parquet\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the zones DataFrame\n",
    "zones = spark.read.csv(\"../data/landing/external/taxi_zones.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the number of events per date, hour, and borough\n",
    "edf_daily = edf.groupBy('Start Date', 'Event Borough').agg(count('Event ID').alias('Number of Events'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the tdf DataFrame with zones to get the borough for PULocationID\n",
    "tdf = tdf.join(zones.select('LocationID', 'borough').withColumnRenamed('borough', 'PUBorough'),\n",
    "               tdf['PULocationID'] == zones['LocationID'], 'left').drop('LocationID')\n",
    "\n",
    "# Join the tdf DataFrame with zones to get the borough for DOLocationID\n",
    "tdf = tdf.join(zones.select('LocationID', 'borough').withColumnRenamed('borough', 'DOBorough'),\n",
    "               tdf['DOLocationID'] == zones['LocationID'], 'left').drop('LocationID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Calculate correlations for hourly trip count\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m temp_hourly_corr \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTMP\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcorr(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhourly_trip_count\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m vis_hourly_corr \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVIS\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcorr(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhourly_trip_count\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m events_hourly_corr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog1p(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of Events\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mcorr(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhourly_trip_count\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Calculate correlations for hourly trip count\n",
    "temp_hourly_corr = df['TMP'].corr(df['hourly_trip_count'])\n",
    "vis_hourly_corr = df['VIS'].corr(df['hourly_trip_count'])\n",
    "events_hourly_corr = np.log1p(df['Number of Events']).corr(df['hourly_trip_count'])\n",
    "\n",
    "# Calculate correlations for daily trip count\n",
    "temp_daily_corr = df['TMP'].corr(df['daily_trip_count'])\n",
    "vis_daily_corr = df['VIS'].corr(df['daily_trip_count'])\n",
    "events_daily_corr = df['Number of Events'].corr(df['daily_trip_count'])\n",
    "\n",
    "# Create a DataFrame to hold the correlation results\n",
    "correlation_matrix = pd.DataFrame({\n",
    "    'Correlation': ['temp_hourly_corr', 'vis_hourly_corr', 'events_hourly_corr', \n",
    "                    'temp_daily_corr', 'vis_daily_corr', 'events_daily_corr'],\n",
    "    'Value': [temp_hourly_corr, vis_hourly_corr, events_hourly_corr, \n",
    "              temp_daily_corr, vis_daily_corr, events_daily_corr]\n",
    "})\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(correlation_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daily demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'pickup_date' and 'PUBorough' to get the sum of trips and average weather data\n",
    "daily_demand = clean_df.groupby(['pickup_date', 'PUBorough']).agg({\n",
    "    'daily_trip_count': 'sum',\n",
    "    'TMP': 'mean',\n",
    "    'VIS': 'mean',\n",
    "    'Number of Events': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Rename the columns to match the desired output\n",
    "daily_demand.rename(columns={\n",
    "    'daily_trip_count': 'total_daily_trips',\n",
    "    'TMP': 'avg_temperature',\n",
    "    'VIS': 'avg_visibility',\n",
    "    'Number of Events': 'total_events'\n",
    "}, inplace=True)\n",
    "\n",
    "# Round the average temperature and visibility to 1 decimal place\n",
    "daily_demand['avg_temperature'] = daily_demand['avg_temperature'].round(1)\n",
    "daily_demand['avg_visibility'] = daily_demand['avg_visibility'].round(1)\n",
    "\n",
    "# Show the first 5 rows of the aggregated result\n",
    "print(daily_demand.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daily Trips by borough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the number of daily trips by PUBorough\n",
    "agg_data_daily = clean_df.groupby('PUBorough').agg({\n",
    "    'daily_trip_count': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Rename the columns to match the expected output\n",
    "agg_data_daily.rename(columns={'PUBorough': 'borough', 'daily_trip_count': 'total_daily_trips'}, inplace=True)\n",
    "\n",
    "# Display the first 5 rows of the aggregated data\n",
    "print(agg_data_daily.head())\n",
    "\n",
    "# Create a bar chart with a log scale\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Create the bar plot using Seaborn\n",
    "sbs.barplot(x='borough', y='total_daily_trips', data=agg_data_daily, ax=ax)\n",
    "\n",
    "# Set the y-axis to a logarithmic scale\n",
    "ax.set_yscale('log')\n",
    "\n",
    "# Set the title of the plot\n",
    "ax.set_title('Total Daily Trips by Borough')\n",
    "\n",
    "# Rotate the x-axis labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the plot\n",
    "fig.savefig(\"../plots/total_daily_trips_by_borough.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickups for each day of week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot number of pick ups per day of the week\n",
    "# Group by 'Day of Week' and count the number of trips\n",
    "trips_per_day_df = clean_df.groupby('Day of Week').agg({'daily_trip_count': 'sum'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the number of trips per day of the week\n",
    "plt.figure(figsize=(12, 6))\n",
    "sbs.barplot(x='Day of Week', y='daily_trip_count', data=trips_per_day_df, order=days_order)\n",
    "plt.title('Number of Trips Per Day of the Week')\n",
    "plt.xlabel('Day of Week')\n",
    "plt.ylabel('Number of Trips')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the plot\n",
    "plt.savefig('../plots/number_of_trips_per_day_of_week.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
