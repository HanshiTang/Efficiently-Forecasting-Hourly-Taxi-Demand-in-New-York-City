{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff8809d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is Proj1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91eccb13-0e7a-43bf-bb7f-c012a1da3f75",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/15 16:24:03 WARN Utils: Your hostname, Hanshis-Laptop.local resolves to a loopback address: 127.0.0.1; using 10.12.200.35 instead (on interface en0)\n",
      "24/08/15 16:24:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/08/15 16:24:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a spark session (which will run spark jobs)\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"ADS Project1\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09910138-5d11-4f1a-9519-9ef381080689",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.parquet.compression.codec\",\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73848e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sbs\n",
    "import geopandas as gpd\n",
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff1e1c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "base_dir = '/Users/hanshitang/Documents/ADS/Proj1/project-1-individual-HanshiTang/data'\n",
    "data_folders = [\n",
    "'landing/tlc_data/2022',\n",
    "'landing/tlc_data/2023',\n",
    "'landing/tlc_data/2024',\n",
    "'raw/tlc_data',\n",
    "'curated/tlc_data/first_clean',\n",
    "'curated/tlc_data/final_data'\n",
    "]\n",
    "\n",
    "for folder in data_folders:\n",
    "    path = os.path.join(base_dir, folder)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        print(f'Created folder: {path}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9080070e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download for 2022-01\n",
      "Finished download for 2022-01\n",
      "Starting download for 2022-02\n",
      "Finished download for 2022-02\n",
      "Starting download for 2022-03\n",
      "Finished download for 2022-03\n",
      "Starting download for 2022-04\n",
      "Finished download for 2022-04\n",
      "Starting download for 2022-05\n",
      "Finished download for 2022-05\n",
      "Starting download for 2022-06\n",
      "Finished download for 2022-06\n",
      "Starting download for 2022-07\n",
      "Finished download for 2022-07\n",
      "Starting download for 2022-08\n",
      "Finished download for 2022-08\n",
      "Starting download for 2022-09\n",
      "Finished download for 2022-09\n",
      "Starting download for 2022-10\n",
      "Finished download for 2022-10\n",
      "Starting download for 2022-11\n",
      "Finished download for 2022-11\n",
      "Starting download for 2022-12\n",
      "Finished download for 2022-12\n",
      "Starting download for 2023-01\n",
      "Finished download for 2023-01\n",
      "Starting download for 2023-02\n",
      "Finished download for 2023-02\n",
      "Starting download for 2023-03\n",
      "Finished download for 2023-03\n",
      "Starting download for 2023-04\n",
      "Finished download for 2023-04\n",
      "Starting download for 2023-05\n",
      "Finished download for 2023-05\n",
      "Starting download for 2023-06\n",
      "Finished download for 2023-06\n",
      "Starting download for 2023-07\n",
      "Finished download for 2023-07\n",
      "Starting download for 2023-08\n",
      "Finished download for 2023-08\n",
      "Starting download for 2023-09\n",
      "Finished download for 2023-09\n",
      "Starting download for 2023-10\n",
      "Finished download for 2023-10\n",
      "Starting download for 2023-11\n",
      "Finished download for 2023-11\n",
      "Starting download for 2023-12\n",
      "Finished download for 2023-12\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "URL_TEMPLATE = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_\"\n",
    "YEAR = ['2022', '2023']\n",
    "MONTH = range(1, 13)\n",
    "output_relative_dir = '/Users/hanshitang/Documents/ADS/Proj1/project-1-individual-HanshiTang/data/landing/tlc_data'\n",
    "\n",
    "for year in YEAR:\n",
    "    for month in MONTH:\n",
    "        print(f'Starting download for {year}-{str(month).zfill(2)}')\n",
    "        month_str = str(month).zfill(2)\n",
    "        url = f'{URL_TEMPLATE}{year}-{month_str}.parquet'\n",
    "        output_dir = f\"{output_relative_dir}/{year}/{year}-{month_str}.parquet\"\n",
    "        \n",
    "        response = requests.get(url, verify=True)\n",
    "        with open(output_dir, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "            \n",
    "        print(f'Finished download for {year}-{month_str}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "058e73fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download for 2024-01\n",
      "Finished download for 2024-01\n",
      "Starting download for 2024-02\n",
      "Finished download for 2024-02\n",
      "Starting download for 2024-03\n",
      "Finished download for 2024-03\n",
      "Starting download for 2024-04\n",
      "Finished download for 2024-04\n",
      "Starting download for 2024-05\n",
      "Finished download for 2024-05\n",
      "Starting download for 2024-06\n",
      "Finished download for 2024-06\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "URL_TEMPLATE = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_\"\n",
    "YEAR = ['2024']\n",
    "MONTH = range(1, 6)\n",
    "output_relative_dir = '/Users/hanshitang/Documents/ADS/Proj1/project-1-individual-HanshiTang/data/landing/tlc_data'\n",
    "\n",
    "for year in YEAR:\n",
    "    for month in MONTH:\n",
    "        print(f'Starting download for {year}-{str(month).zfill(2)}')\n",
    "        month_str = str(month).zfill(2)\n",
    "        url = f'{URL_TEMPLATE}{year}-{month_str}.parquet'\n",
    "        output_dir = f\"{output_relative_dir}/{year}/{year}-{month_str}.parquet\"\n",
    "        \n",
    "        response = requests.get(url, verify=True)\n",
    "        with open(output_dir, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "            \n",
    "        print(f'Finished download for {year}-{month_str}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa07b9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取2019年的Parquet文件\n",
    "df_2019 = spark.read.parquet('../data/landing/tlc_data/2019/*.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4249ad1b-40b8-4815-94a9-4d5947b9dd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/landing/tlc_data\"\n",
    "df_2019_1 = spark.read.parquet(path + \"/2019/2019-01.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6dd3388-105d-4999-a746-01b44eb776d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|       1| 2019-01-01 00:46:40|  2019-01-01 00:53:20|            1.0|          1.5|       1.0|                 N|         151|         239|           1|        7.0|  0.5|    0.5|      1.65|         0.0|                  0.3|        9.95|                NULL|       NULL|\n",
      "|       1| 2019-01-01 00:59:47|  2019-01-01 01:18:59|            1.0|          2.6|       1.0|                 N|         239|         246|           1|       14.0|  0.5|    0.5|       1.0|         0.0|                  0.3|        16.3|                NULL|       NULL|\n",
      "|       2| 2018-12-21 13:48:30|  2018-12-21 13:52:40|            3.0|          0.0|       1.0|                 N|         236|         236|           1|        4.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         5.8|                NULL|       NULL|\n",
      "|       2| 2018-11-28 15:52:25|  2018-11-28 15:55:45|            5.0|          0.0|       1.0|                 N|         193|         193|           2|        3.5|  0.5|    0.5|       0.0|         0.0|                  0.3|        7.55|                NULL|       NULL|\n",
      "|       2| 2018-11-28 15:56:57|  2018-11-28 15:58:33|            5.0|          0.0|       2.0|                 N|         193|         193|           2|       52.0|  0.0|    0.5|       0.0|         0.0|                  0.3|       55.55|                NULL|       NULL|\n",
      "|       2| 2018-11-28 16:25:49|  2018-11-28 16:28:26|            5.0|          0.0|       1.0|                 N|         193|         193|           2|        3.5|  0.5|    0.5|       0.0|        5.76|                  0.3|       13.31|                NULL|       NULL|\n",
      "|       2| 2018-11-28 16:29:37|  2018-11-28 16:33:43|            5.0|          0.0|       2.0|                 N|         193|         193|           2|       52.0|  0.0|    0.5|       0.0|         0.0|                  0.3|       55.55|                NULL|       NULL|\n",
      "|       1| 2019-01-01 00:21:28|  2019-01-01 00:28:37|            1.0|          1.3|       1.0|                 N|         163|         229|           1|        6.5|  0.5|    0.5|      1.25|         0.0|                  0.3|        9.05|                NULL|       NULL|\n",
      "|       1| 2019-01-01 00:32:01|  2019-01-01 00:45:39|            1.0|          3.7|       1.0|                 N|         229|           7|           1|       13.5|  0.5|    0.5|       3.7|         0.0|                  0.3|        18.5|                NULL|       NULL|\n",
      "|       1| 2019-01-01 00:57:32|  2019-01-01 01:09:32|            2.0|          2.1|       1.0|                 N|         141|         234|           1|       10.0|  0.5|    0.5|       1.7|         0.0|                  0.3|        13.0|                NULL|       NULL|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 显示数据 \n",
    "df_2019_1.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1c88869-10c8-4ac3-b035-1150781e97f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: long (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- passenger_count: double (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: double (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: long (nullable = true)\n",
      " |-- DOLocationID: long (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- airport_fee: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_2019_1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990ad4d4-8c9d-4d8a-bfbc-747b164a6302",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a44bc6-cd84-4d0f-9a65-61d405d79394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5259a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
