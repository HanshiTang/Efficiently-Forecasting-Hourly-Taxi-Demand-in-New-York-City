{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing_4\n",
    "This notebook merges 3 preprocessed datasets and prepares for EDA_hourly and model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sbs\n",
    "import geopandas as gpd\n",
    "import folium "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/31 22:47:50 WARN Utils: Your hostname, Hanshis-Laptop.local resolves to a loopback address: 127.0.0.1; using 10.12.218.66 instead (on interface en0)\n",
      "24/08/31 22:47:50 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/08/31 22:47:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a spark session with increased memory allocation\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"ADS Project1\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.driver.memory\", \"8g\")  # Set the driver memory to 8GB\n",
    "    .config(\"spark.executor.memory\", \"8g\")  # Set the executor memory to 8GB\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.parquet.compression.codec\",\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# read the data from preprocessed tlc data\n",
    "tdf = spark.read.parquet(\"../data/raw/tlc_df.parquet\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the preprocessed weather data\n",
    "wdf = spark.read.csv(\"../data/raw/NYC_weather_raw.csv\", header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the preprocessed event data\n",
    "edf = spark.read.parquet(\"../data/raw/NYC_Permitted_Event_Information_Historical.parquet\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+-------------+-----------+------------+-----------+------------+-------------+\n",
      "|PULocationID|DOLocationID|trip_distance|pickup_hour|dropoff_hour|pickup_date|dropoff_date|trip_duration|\n",
      "+------------+------------+-------------+-----------+------------+-----------+------------+-------------+\n",
      "|         249|         179|          7.1|          0|           1| 2023-07-01|  2023-07-01|         32.0|\n",
      "|         132|         230|         18.9|          0|           1| 2023-07-01|  2023-07-01|         48.0|\n",
      "|         164|         230|         1.24|          0|           0| 2023-07-01|  2023-07-01|          8.0|\n",
      "|         132|         131|         14.8|          0|           0| 2023-07-01|  2023-07-01|         21.0|\n",
      "|         144|         198|          9.6|          0|           0| 2023-07-01|  2023-07-01|         28.0|\n",
      "+------------+------------+-------------+-----------+------------+-----------+------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show 5 rows of the tlc data\n",
    "tdf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use 4 dcimal places for the float values in weather data\n",
    "wdf = wdf.withColumn(\"CIG\", round(col(\"CIG\"), 4))\n",
    "wdf = wdf.withColumn(\"WND\", round(col(\"WND\"), 4))\n",
    "wdf = wdf.withColumn(\"TMP\", round(col(\"TMP\"), 4))\n",
    "wdf = wdf.withColumn(\"DEW\", round(col(\"DEW\"), 4))\n",
    "wdf = wdf.withColumn(\"SLP\", round(col(\"SLP\"), 4))\n",
    "wdf = wdf.withColumn(\"VIS\", round(col(\"VIS\"), 4))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+-------+-----+-----+----+----+------+\n",
      "|      DATE|HOUR|    CIG|  WND|  VIS| TMP| DEW|   SLP|\n",
      "+----------+----+-------+-----+-----+----+----+------+\n",
      "|2023-07-01|   0|22000.0|2.632|965.6|23.9|13.3|1017.1|\n",
      "|2023-07-01|   1|22000.0|2.632|965.6|23.3|13.3|1017.6|\n",
      "|2023-07-01|   2|22000.0|2.632|965.6|23.3|12.8|1017.8|\n",
      "|2023-07-01|   3|22000.0|  3.1|965.6|22.8|12.8|1017.7|\n",
      "|2023-07-01|   4|22000.0|  1.5|965.6|22.8|11.7|1017.4|\n",
      "+----------+----+-------+-----+-----+----+----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show 5 rows of the weather data\n",
    "wdf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+----------+----------+--------+-------------+-------------+--------------------+\n",
      "|Event ID|Start Date|Start Hour|  End Date|End Hour|   Event Type|Event Borough|    Location Details|\n",
      "+--------+----------+----------+----------+--------+-------------+-------------+--------------------+\n",
      "|  725004|2023-09-05|         9|2023-09-05|      20|Sport - Youth|     Brooklyn|Commodore Barry Park|\n",
      "|  720627|2023-09-25|        16|2023-09-25|      20|Sport - Adult|     Brooklyn|Red Hook Recreati...|\n",
      "|  723466|2023-09-26|         9|2023-09-26|      15|Sport - Youth|        Bronx|       Colgate Close|\n",
      "|  732945|2023-09-19|        15|2023-09-19|      18|Sport - Adult|     Brooklyn|   Calvert Vaux Park|\n",
      "|  715391|2023-09-25|         8|2023-09-25|      19|Sport - Youth|     Brooklyn|Red Hook Recreati...|\n",
      "+--------+----------+----------+----------+--------+-------------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show 5 rows of the event data\n",
    "edf.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation for hourly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map taxi zones to boroughs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the zones DataFrame\n",
    "zones = spark.read.csv(\"../data/landing/external/taxi_zones.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the tdf DataFrame with zones to get the borough for PULocationID\n",
    "tdf = tdf.join(zones.select('LocationID', 'borough').withColumnRenamed('borough', 'PUBorough'),\n",
    "               tdf['PULocationID'] == zones['LocationID'], 'left').drop('LocationID')\n",
    "\n",
    "# Join the tdf DataFrame with zones to get the borough for DOLocationID\n",
    "tdf = tdf.join(zones.select('LocationID', 'borough').withColumnRenamed('borough', 'DOBorough'),\n",
    "               tdf['DOLocationID'] == zones['LocationID'], 'left').drop('LocationID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+-------------+-----------+------------+-----------+------------+-------------+---------+---------+\n",
      "|PULocationID|DOLocationID|trip_distance|pickup_hour|dropoff_hour|pickup_date|dropoff_date|trip_duration|PUBorough|DOBorough|\n",
      "+------------+------------+-------------+-----------+------------+-----------+------------+-------------+---------+---------+\n",
      "|         249|         179|          7.1|          0|           1| 2023-07-01|  2023-07-01|         32.0|Manhattan|   Queens|\n",
      "|         132|         230|         18.9|          0|           1| 2023-07-01|  2023-07-01|         48.0|   Queens|Manhattan|\n",
      "|         164|         230|         1.24|          0|           0| 2023-07-01|  2023-07-01|          8.0|Manhattan|Manhattan|\n",
      "|         132|         131|         14.8|          0|           0| 2023-07-01|  2023-07-01|         21.0|   Queens|   Queens|\n",
      "|         144|         198|          9.6|          0|           0| 2023-07-01|  2023-07-01|         28.0|Manhattan|   Queens|\n",
      "|         249|         170|         1.94|          0|           0| 2023-07-01|  2023-07-01|         13.0|Manhattan|Manhattan|\n",
      "|          79|         170|         2.32|          0|           1| 2023-07-01|  2023-07-01|         10.0|Manhattan|Manhattan|\n",
      "|         132|         230|        18.37|          0|           1| 2023-07-01|  2023-07-01|         40.0|   Queens|Manhattan|\n",
      "|         137|          50|         3.09|          0|           0| 2023-07-01|  2023-07-01|         15.0|Manhattan|Manhattan|\n",
      "|         114|         144|         1.05|          0|           0| 2023-07-01|  2023-07-01|          8.0|Manhattan|Manhattan|\n",
      "|         261|           4|         2.73|          0|           0| 2023-07-01|  2023-07-01|         16.0|Manhattan|Manhattan|\n",
      "|         162|         230|          0.6|          0|           0| 2023-07-01|  2023-07-01|          9.0|Manhattan|Manhattan|\n",
      "|         107|         143|          3.9|          0|           1| 2023-07-01|  2023-07-01|         18.0|Manhattan|Manhattan|\n",
      "|         234|         249|         0.88|          0|           0| 2023-07-01|  2023-07-01|          7.0|Manhattan|Manhattan|\n",
      "|         148|         237|         4.87|          0|           1| 2023-07-01|  2023-07-01|         17.0|Manhattan|Manhattan|\n",
      "+------------+------------+-------------+-----------+------------+-----------+------------+-------------+---------+---------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show 15 rows of the tlc data\n",
    "tdf.show(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|          PUBorough|\n",
      "+-------------------+\n",
      "|0.00734753204628976|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show percentage of missing values in PUBorough column of the tlc data\n",
    "tdf.select((F.sum(F.col(\"PUBorough\").isNull().cast(\"int\"))/F.count(F.col(\"PUBorough\"))).alias(\"PUBorough\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+-------------+-----------+------------+-----------+------------+-------------+-------------------+-------------------+\n",
      "|PULocationID|DOLocationID|trip_distance|pickup_hour|dropoff_hour|pickup_date|dropoff_date|trip_duration|          PUBorough|          DOBorough|\n",
      "+------------+------------+-------------+-----------+------------+-----------+------------+-------------+-------------------+-------------------+\n",
      "|         0.0|         0.0|          0.0|        0.0|         0.0|        0.0|         0.0|          0.0|0.00734753204628976|0.01304270366266107|\n",
      "+------------+------------+-------------+-----------+------------+-----------+------------+-------------+-------------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# show percentage of missing values in all columns of the tlc data\n",
    "tdf.select([(F.sum(F.col(c).isNull().cast(\"int\"))/F.count(F.col(c))).alias(c) for c in tdf.columns]).show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with missing values in PUBorough and DOBorough column\n",
    "tdf = tdf.filter(F.col(\"PUBorough\").isNotNull())\n",
    "tdf = tdf.filter(F.col(\"DOBorough\").isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert pickup_date and pickup_hour to a timestamp and create Time column\n",
    "tdf = tdf.withColumn(\n",
    "    'Time', \n",
    "    to_timestamp(concat_ws(' ', col('pickup_date'), col('pickup_hour')))\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourly_agg = tdf.groupBy(['pickup_date', 'pickup_hour', \"PUBorough\"]).agg({\n",
    "    '*': 'count', \n",
    "}).withColumnRenamed('count(1)', 'hourly_trip_count') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tdf drop the Time column \n",
    "tdf = tdf.drop('Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the hourly aggregated data by date pickup_date and pickup_hour\n",
    "df_hourly_agg = df_hourly_agg.sort('pickup_date', 'pickup_hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    " # drop pickup_date if it's outside of the pickup_date range of 2023-07-01 to 2023-12-31\n",
    "df_hourly_agg = df_hourly_agg.filter((col('pickup_date') >= '2023-07-01') & (col('pickup_date') <= '2023-12-31'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 30:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-----------------+-------------------------+\n",
      "|pickup_date_missing|pickup_hour_missing|PUBorough_missing|hourly_trip_count_missing|\n",
      "+-------------------+-------------------+-----------------+-------------------------+\n",
      "|                0.0|                0.0|              0.0|                      0.0|\n",
      "+-------------------+-------------------+-----------------+-------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# check percentage of missing values in each column for df_hourly_agg\n",
    "df_hourly_agg.agg(*[\n",
    "    (1 - (F.count(c) / F.count('*'))).alias(c + '_missing')\n",
    "    for c in df_hourly_agg.columns\n",
    "]).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation of number of events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the number of events per date, hour, and borough\n",
    "edf_hourly = edf.groupBy('Start Date', 'Start Hour', 'Event Borough').agg(count('Event ID').alias('Number of Events'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+----------+----------+--------+-------------+-------------+--------------------+\n",
      "|Event ID|Start Date|Start Hour|  End Date|End Hour|   Event Type|Event Borough|    Location Details|\n",
      "+--------+----------+----------+----------+--------+-------------+-------------+--------------------+\n",
      "|  725004|2023-09-05|         9|2023-09-05|      20|Sport - Youth|     Brooklyn|Commodore Barry Park|\n",
      "|  720627|2023-09-25|        16|2023-09-25|      20|Sport - Adult|     Brooklyn|Red Hook Recreati...|\n",
      "|  723466|2023-09-26|         9|2023-09-26|      15|Sport - Youth|        Bronx|       Colgate Close|\n",
      "|  732945|2023-09-19|        15|2023-09-19|      18|Sport - Adult|     Brooklyn|   Calvert Vaux Park|\n",
      "|  715391|2023-09-25|         8|2023-09-25|      19|Sport - Youth|     Brooklyn|Red Hook Recreati...|\n",
      "+--------+----------+----------+----------+--------+-------------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show edf\n",
    "edf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-------------+----------------+\n",
      "|Start Date|Start Hour|Event Borough|Number of Events|\n",
      "+----------+----------+-------------+----------------+\n",
      "|2023-09-28|         9|     Brooklyn|             292|\n",
      "|2023-09-16|        13|        Bronx|             122|\n",
      "|2023-09-17|        12|        Bronx|              96|\n",
      "|2023-11-04|         8|       Queens|            2430|\n",
      "|2023-11-23|         8|       Queens|             947|\n",
      "+----------+----------+-------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "edf_hourly.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join hourly datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+-------+-----+-----+----+----+------+\n",
      "|      DATE|HOUR|    CIG|  WND|  VIS| TMP| DEW|   SLP|\n",
      "+----------+----+-------+-----+-----+----+----+------+\n",
      "|2023-07-01|   0|22000.0|2.632|965.6|23.9|13.3|1017.1|\n",
      "|2023-07-01|   1|22000.0|2.632|965.6|23.3|13.3|1017.6|\n",
      "|2023-07-01|   2|22000.0|2.632|965.6|23.3|12.8|1017.8|\n",
      "|2023-07-01|   3|22000.0|  3.1|965.6|22.8|12.8|1017.7|\n",
      "|2023-07-01|   4|22000.0|  1.5|965.6|22.8|11.7|1017.4|\n",
      "+----------+----+-------+-----+-----+----+----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show 5 rows for the weather data\n",
    "wdf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+---------+-----------------+\n",
      "|pickup_date|pickup_hour|PUBorough|hourly_trip_count|\n",
      "+-----------+-----------+---------+-----------------+\n",
      "| 2023-07-01|          0|Manhattan|             3092|\n",
      "| 2023-07-01|          0|   Queens|              361|\n",
      "| 2023-07-01|          0| Brooklyn|               32|\n",
      "| 2023-07-01|          1|   Queens|              163|\n",
      "| 2023-07-01|          1| Brooklyn|               33|\n",
      "+-----------+-----------+---------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# show 5 rows for the df_hourly_agg data\n",
    "df_hourly_agg.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the weather data with the df_hourly_agg data by pickup_date and pickup_hour\n",
    "merged1 = df_hourly_agg.join(wdf, (df_hourly_agg['pickup_date'] == wdf['DATE']) & (df_hourly_agg['pickup_hour'] == wdf['HOUR']), 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by pickup_date and pickup_hour\n",
    "merged1 = merged1.sort('pickup_date', 'pickup_hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop DATE and HOUR columns\n",
    "merged1 = merged1.drop('DATE', 'HOUR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 49:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+---------+-----------------+-------+-----+-----+----+----+------+\n",
      "|pickup_date|pickup_hour|PUBorough|hourly_trip_count|    CIG|  WND|  VIS| TMP| DEW|   SLP|\n",
      "+-----------+-----------+---------+-----------------+-------+-----+-----+----+----+------+\n",
      "| 2023-07-01|          0|Manhattan|             3092|22000.0|2.632|965.6|23.9|13.3|1017.1|\n",
      "| 2023-07-01|          0|   Queens|              361|22000.0|2.632|965.6|23.9|13.3|1017.1|\n",
      "| 2023-07-01|          0| Brooklyn|               32|22000.0|2.632|965.6|23.9|13.3|1017.1|\n",
      "| 2023-07-01|          1|   Queens|              163|22000.0|2.632|965.6|23.3|13.3|1017.6|\n",
      "| 2023-07-01|          1| Brooklyn|               33|22000.0|2.632|965.6|23.3|13.3|1017.6|\n",
      "| 2023-07-01|          1|    Bronx|                3|22000.0|2.632|965.6|23.3|13.3|1017.6|\n",
      "| 2023-07-01|          1|Manhattan|             2685|22000.0|2.632|965.6|23.3|13.3|1017.6|\n",
      "| 2023-07-01|          2|Manhattan|             1996|22000.0|2.632|965.6|23.3|12.8|1017.8|\n",
      "| 2023-07-01|          2|   Queens|               84|22000.0|2.632|965.6|23.3|12.8|1017.8|\n",
      "| 2023-07-01|          2| Brooklyn|               27|22000.0|2.632|965.6|23.3|12.8|1017.8|\n",
      "| 2023-07-01|          2|    Bronx|                1|22000.0|2.632|965.6|23.3|12.8|1017.8|\n",
      "| 2023-07-01|          2|      EWR|                1|22000.0|2.632|965.6|23.3|12.8|1017.8|\n",
      "| 2023-07-01|          3| Brooklyn|               27|22000.0|  3.1|965.6|22.8|12.8|1017.7|\n",
      "| 2023-07-01|          3|Manhattan|             1372|22000.0|  3.1|965.6|22.8|12.8|1017.7|\n",
      "| 2023-07-01|          3|   Queens|               48|22000.0|  3.1|965.6|22.8|12.8|1017.7|\n",
      "+-----------+-----------+---------+-----------------+-------+-----+-----+----+----+------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# show 5 rows of the merged data\n",
    "merged1.show(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 55:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-----------------+-------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|pickup_date_missing|pickup_hour_missing|PUBorough_missing|hourly_trip_count_missing|         CIG_missing|         WND_missing|         VIS_missing|         TMP_missing|         DEW_missing|         SLP_missing|\n",
      "+-------------------+-------------------+-----------------+-------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                0.0|                0.0|              0.0|                      0.0|0.004823355193568912|0.004823355193568912|0.004823355193568912|0.004823355193568912|0.004823355193568912|0.004823355193568912|\n",
      "+-------------------+-------------------+-----------------+-------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# check missing values in the merged data\n",
    "merged1.agg(*[\n",
    "    (1 - (F.count(c) / F.count('*'))).alias(c + '_missing')\n",
    "    for c in merged1.columns\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a window specification with proper partitioning\n",
    "window_spec = Window.partitionBy(\"pickup_date\").orderBy(\"pickup_hour\").rowsBetween(-sys.maxsize, 0)\n",
    "\n",
    "# Apply forward fill to the missing weather columns\n",
    "merged1 = merged1.withColumn(\"CIG\", last(col(\"CIG\"), ignorenulls=True).over(window_spec))\n",
    "merged1 = merged1.withColumn(\"WND\", last(col(\"WND\"), ignorenulls=True).over(window_spec))\n",
    "merged1 = merged1.withColumn(\"VIS\", last(col(\"VIS\"), ignorenulls=True).over(window_spec))\n",
    "merged1 = merged1.withColumn(\"TMP\", last(col(\"TMP\"), ignorenulls=True).over(window_spec))\n",
    "merged1 = merged1.withColumn(\"DEW\", last(col(\"DEW\"), ignorenulls=True).over(window_spec))\n",
    "merged1 = merged1.withColumn(\"SLP\", last(col(\"SLP\"), ignorenulls=True).over(window_spec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-----------------+-------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|pickup_date_missing|pickup_hour_missing|PUBorough_missing|hourly_trip_count_missing|         CIG_missing|         WND_missing|         VIS_missing|         TMP_missing|         DEW_missing|         SLP_missing|\n",
      "+-------------------+-------------------+-----------------+-------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                0.0|                0.0|              0.0|                      0.0|0.004188703194415111|0.004188703194415111|0.004188703194415111|0.004188703194415111|0.004188703194415111|0.004188703194415111|\n",
      "+-------------------+-------------------+-----------------+-------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check missing values in merged1\n",
    "merged1.agg(*[\n",
    "    (1 - (F.count(c) / F.count('*'))).alias(c + '_missing')\n",
    "    for c in merged1.columns\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# impute missing values with the mean of the column including CIG, WND, VIS, TMP, DEW, and SLP\n",
    "merged1 = merged1.fillna(merged1.agg(*[\n",
    "    F.mean(c).alias(c)\n",
    "    for c in [\"CIG\", \"WND\", \"VIS\", \"TMP\", \"DEW\", \"SLP\"]\n",
    "]).first().asDict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-----------------+-------------------------+-----------+-----------+-----------+-----------+-----------+-----------+\n",
      "|pickup_date_missing|pickup_hour_missing|PUBorough_missing|hourly_trip_count_missing|CIG_missing|WND_missing|VIS_missing|TMP_missing|DEW_missing|SLP_missing|\n",
      "+-------------------+-------------------+-----------------+-------------------------+-----------+-----------+-----------+-----------+-----------+-----------+\n",
      "|                0.0|                0.0|              0.0|                      0.0|        0.0|        0.0|        0.0|        0.0|        0.0|        0.0|\n",
      "+-------------------+-------------------+-----------------+-------------------------+-----------+-----------+-----------+-----------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check missing values in merged1\n",
    "merged1.agg(*[\n",
    "    (1 - (F.count(c) / F.count('*'))).alias(c + '_missing')\n",
    "    for c in merged1.columns\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+---------+-----------------+-------+-----+-----+----+----+------+\n",
      "|pickup_date|pickup_hour|PUBorough|hourly_trip_count|    CIG|  WND|  VIS| TMP| DEW|   SLP|\n",
      "+-----------+-----------+---------+-----------------+-------+-----+-----+----+----+------+\n",
      "| 2023-07-01|          0|Manhattan|             3092|22000.0|2.632|965.6|23.9|13.3|1017.1|\n",
      "| 2023-07-01|          0|   Queens|              361|22000.0|2.632|965.6|23.9|13.3|1017.1|\n",
      "| 2023-07-01|          0| Brooklyn|               32|22000.0|2.632|965.6|23.9|13.3|1017.1|\n",
      "| 2023-07-01|          1|   Queens|              163|22000.0|2.632|965.6|23.3|13.3|1017.6|\n",
      "| 2023-07-01|          1|    Bronx|                3|22000.0|2.632|965.6|23.3|13.3|1017.6|\n",
      "| 2023-07-01|          1| Brooklyn|               33|22000.0|2.632|965.6|23.3|13.3|1017.6|\n",
      "| 2023-07-01|          1|Manhattan|             2685|22000.0|2.632|965.6|23.3|13.3|1017.6|\n",
      "| 2023-07-01|          2|Manhattan|             1996|22000.0|2.632|965.6|23.3|12.8|1017.8|\n",
      "| 2023-07-01|          2| Brooklyn|               27|22000.0|2.632|965.6|23.3|12.8|1017.8|\n",
      "| 2023-07-01|          2|   Queens|               84|22000.0|2.632|965.6|23.3|12.8|1017.8|\n",
      "| 2023-07-01|          2|    Bronx|                1|22000.0|2.632|965.6|23.3|12.8|1017.8|\n",
      "| 2023-07-01|          2|      EWR|                1|22000.0|2.632|965.6|23.3|12.8|1017.8|\n",
      "| 2023-07-01|          3| Brooklyn|               27|22000.0|  3.1|965.6|22.8|12.8|1017.7|\n",
      "| 2023-07-01|          3|   Queens|               48|22000.0|  3.1|965.6|22.8|12.8|1017.7|\n",
      "| 2023-07-01|          3|Manhattan|             1372|22000.0|  3.1|965.6|22.8|12.8|1017.7|\n",
      "+-----------+-----------+---------+-----------------+-------+-----+-----+----+----+------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show 15 rows of the merged1 data\n",
    "merged1.show(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the edf_hourly data by Start Date and Start Hour\n",
    "edf_hourly = edf_hourly.sort('Start Date', 'Start Hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+---------------------+------------------------+\n",
      "|Start Date_missing|Start Hour_missing|Event Borough_missing|Number of Events_missing|\n",
      "+------------------+------------------+---------------------+------------------------+\n",
      "|               0.0|               0.0|                  0.0|                     0.0|\n",
      "+------------------+------------------+---------------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check missing values in edf_hourly\n",
    "edf_hourly.agg(*[\n",
    "    (1 - (F.count(c) / F.count('*'))).alias(c + '_missing')\n",
    "    for c in edf_hourly.columns\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the edf_hourly data with the merged1 data by pickup_date, and pickup_hour and PUBorough\n",
    "merged2 = merged1.join(edf_hourly, (merged1['pickup_date'] == edf_hourly['Start Date']) \n",
    "                       & (merged1['pickup_hour'] == edf_hourly['Start Hour']) \n",
    "                       & (merged1['PUBorough'] == edf_hourly['Event Borough']), 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by pickup_date and pickup_hour\n",
    "merged2 = merged2.sort('pickup_date', 'pickup_hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-----------------+-------------------------+-----------+-----------+-----------+-----------+-----------+-----------+------------------+------------------+---------------------+------------------------+\n",
      "|pickup_date_missing|pickup_hour_missing|PUBorough_missing|hourly_trip_count_missing|CIG_missing|WND_missing|VIS_missing|TMP_missing|DEW_missing|SLP_missing|Start Date_missing|Start Hour_missing|Event Borough_missing|Number of Events_missing|\n",
      "+-------------------+-------------------+-----------------+-------------------------+-----------+-----------+-----------+-----------+-----------+-----------+------------------+------------------+---------------------+------------------------+\n",
      "|                0.0|                0.0|              0.0|                      0.0|        0.0|        0.0|        0.0|        0.0|        0.0|        0.0|0.3958112968055849|0.3958112968055849|   0.3958112968055849|      0.3958112968055849|\n",
      "+-------------------+-------------------+-----------------+-------------------------+-----------+-----------+-----------+-----------+-----------+-----------+------------------+------------------+---------------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check missing values in merged2\n",
    "merged2.agg(*[\n",
    "    (1 - (F.count(c) / F.count('*'))).alias(c + '_missing')\n",
    "    for c in merged2.columns\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|    PUBorough|count|\n",
      "+-------------+-----+\n",
      "|       Queens| 2504|\n",
      "|          EWR|  196|\n",
      "|     Brooklyn| 2162|\n",
      "|Staten Island|  208|\n",
      "|    Manhattan| 1953|\n",
      "|        Bronx| 2332|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# chcck when are the missing values in the merged2 data accoringd to borough\n",
    "merged2.filter(col('Number of Events').isNull()).groupBy('PUBorough').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|pickup_hour|count|\n",
      "+-----------+-----+\n",
      "|          0|  199|\n",
      "|          1|  596|\n",
      "|          2|  745|\n",
      "|          3|  822|\n",
      "|          4| 1547|\n",
      "|          5|  976|\n",
      "|          6|  618|\n",
      "|          7|  278|\n",
      "|          8|    8|\n",
      "|          9|   12|\n",
      "|         10|   15|\n",
      "|         11|  107|\n",
      "|         12|  104|\n",
      "|         13|   95|\n",
      "|         14|   67|\n",
      "|         15|   54|\n",
      "|         16|   32|\n",
      "|         17|  116|\n",
      "|         18|   87|\n",
      "|         19|  317|\n",
      "+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# missing values in the Number of Events column by hour and sorted by hour\n",
    "merged2.filter(col('Number of Events').isNull()).groupBy('pickup_hour').count().sort('pickup_hour').show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling missing data\n",
    "The assumption is no events occured if number of event in Null\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing values with 0 for the Number of Events column and \n",
    "merged2 = merged2.fillna(0, subset=['Number of Events'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the Start Date, Start Hour, and Event Borough columns\n",
    "merged2 = merged2.drop('Start Date', 'Start Hour', 'Event Borough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-------------+-----------------+----------+-----+---------+-------+-------+---------+----------------+\n",
      "|pickup_date|pickup_hour|    PUBorough|hourly_trip_count|       CIG|  WND|      VIS|    TMP|    DEW|      SLP|Number of Events|\n",
      "+-----------+-----------+-------------+-----------------+----------+-----+---------+-------+-------+---------+----------------+\n",
      "| 2023-07-01|          0|    Manhattan|             3092|   22000.0|2.632|    965.6|   23.9|   13.3|   1017.1|              77|\n",
      "| 2023-07-01|          0|       Queens|              361|   22000.0|2.632|    965.6|   23.9|   13.3|   1017.1|              20|\n",
      "| 2023-07-01|          0|     Brooklyn|               32|   22000.0|2.632|    965.6|   23.9|   13.3|   1017.1|              25|\n",
      "| 2023-07-01|          1|       Queens|              163|   22000.0|2.632|    965.6|   23.3|   13.3|   1017.6|               0|\n",
      "| 2023-07-01|          1|        Bronx|                3|   22000.0|2.632|    965.6|   23.3|   13.3|   1017.6|               0|\n",
      "| 2023-07-01|          1|     Brooklyn|               33|   22000.0|2.632|    965.6|   23.3|   13.3|   1017.6|               0|\n",
      "| 2023-07-01|          1|    Manhattan|             2685|   22000.0|2.632|    965.6|   23.3|   13.3|   1017.6|               0|\n",
      "| 2023-07-01|          2|    Manhattan|             1996|   22000.0|2.632|    965.6|   23.3|   12.8|   1017.8|               0|\n",
      "| 2023-07-01|          2|     Brooklyn|               27|   22000.0|2.632|    965.6|   23.3|   12.8|   1017.8|               0|\n",
      "| 2023-07-01|          2|       Queens|               84|   22000.0|2.632|    965.6|   23.3|   12.8|   1017.8|               0|\n",
      "| 2023-07-01|          2|        Bronx|                1|   22000.0|2.632|    965.6|   23.3|   12.8|   1017.8|               0|\n",
      "| 2023-07-01|          2|          EWR|                1|   22000.0|2.632|    965.6|   23.3|   12.8|   1017.8|               0|\n",
      "| 2023-07-01|          3|     Brooklyn|               27|   22000.0|  3.1|    965.6|   22.8|   12.8|   1017.7|               0|\n",
      "| 2023-07-01|          3|       Queens|               48|   22000.0|  3.1|    965.6|   22.8|   12.8|   1017.7|               0|\n",
      "| 2023-07-01|          3|    Manhattan|             1372|   22000.0|  3.1|    965.6|   22.8|   12.8|   1017.7|               0|\n",
      "| 2023-07-01|          4|    Manhattan|              806|11279.5968|2.632|1265.5238|17.2297|11.5355|1016.0976|               0|\n",
      "| 2023-07-01|          4|    Manhattan|              806|   22000.0|  1.5|    965.6|   22.8|   11.7|   1017.4|               0|\n",
      "| 2023-07-01|          4|     Brooklyn|               21|11279.5968|2.632|1265.5238|17.2297|11.5355|1016.0976|               0|\n",
      "| 2023-07-01|          4|     Brooklyn|               21|   22000.0|  1.5|    965.6|   22.8|   11.7|   1017.4|               0|\n",
      "| 2023-07-01|          4|        Bronx|                3|11279.5968|2.632|1265.5238|17.2297|11.5355|1016.0976|               0|\n",
      "| 2023-07-01|          4|        Bronx|                3|   22000.0|  1.5|    965.6|   22.8|   11.7|   1017.4|               0|\n",
      "| 2023-07-01|          4|       Queens|               23|11279.5968|2.632|1265.5238|17.2297|11.5355|1016.0976|               0|\n",
      "| 2023-07-01|          4|       Queens|               23|   22000.0|  1.5|    965.6|   22.8|   11.7|   1017.4|               0|\n",
      "| 2023-07-01|          5|       Queens|               46|   22000.0|2.632|    965.6|   22.2|   12.2|   1017.5|               0|\n",
      "| 2023-07-01|          5|    Manhattan|              356|   22000.0|2.632|    965.6|   22.2|   12.2|   1017.5|               0|\n",
      "| 2023-07-01|          5|        Bronx|                1|   22000.0|2.632|    965.6|   22.2|   12.2|   1017.5|               0|\n",
      "| 2023-07-01|          5|     Brooklyn|                5|   22000.0|2.632|    965.6|   22.2|   12.2|   1017.5|               0|\n",
      "| 2023-07-01|          6|    Manhattan|              613|   22000.0|  2.6|    965.6|   21.7|   12.8|   1017.1|              20|\n",
      "| 2023-07-01|          6|       Queens|              125|   22000.0|  2.6|    965.6|   21.7|   12.8|   1017.1|               0|\n",
      "| 2023-07-01|          6|        Bronx|                7|   22000.0|  2.6|    965.6|   21.7|   12.8|   1017.1|              20|\n",
      "| 2023-07-01|          6|     Brooklyn|                4|   22000.0|  2.6|    965.6|   21.7|   12.8|   1017.1|               0|\n",
      "| 2023-07-01|          7|    Manhattan|              905|   22000.0|  1.5|    965.6|   21.1|   13.3|   1017.2|             132|\n",
      "| 2023-07-01|          7|        Bronx|                1|   22000.0|  1.5|    965.6|   21.1|   13.3|   1017.2|              34|\n",
      "| 2023-07-01|          7|       Queens|              136|   22000.0|  1.5|    965.6|   21.1|   13.3|   1017.2|              40|\n",
      "| 2023-07-01|          7|Staten Island|                1|   22000.0|  1.5|    965.6|   21.1|   13.3|   1017.2|             100|\n",
      "| 2023-07-01|          7|     Brooklyn|                6|   22000.0|  1.5|    965.6|   21.1|   13.3|   1017.2|             100|\n",
      "| 2023-07-01|          8|    Manhattan|             1403|   22000.0|  1.5|   1126.5|   21.1|   14.4|   1017.4|            1480|\n",
      "| 2023-07-01|          8|        Bronx|                6|   22000.0|  1.5|   1126.5|   21.1|   14.4|   1017.4|            1162|\n",
      "| 2023-07-01|          8|       Queens|              172|   22000.0|  1.5|   1126.5|   21.1|   14.4|   1017.4|            1578|\n",
      "| 2023-07-01|          8|     Brooklyn|               10|   22000.0|  1.5|   1126.5|   21.1|   14.4|   1017.4|            1933|\n",
      "| 2023-07-01|          9|       Queens|              246|   22000.0|2.632|    965.6|   20.6|   15.0|   1017.6|            1049|\n",
      "| 2023-07-01|          9|     Brooklyn|               16|   22000.0|2.632|    965.6|   20.6|   15.0|   1017.6|            1079|\n",
      "| 2023-07-01|          9|    Manhattan|             2138|   22000.0|2.632|    965.6|   20.6|   15.0|   1017.6|             919|\n",
      "| 2023-07-01|          9|        Bronx|                7|   22000.0|2.632|    965.6|   20.6|   15.0|   1017.6|             720|\n",
      "| 2023-07-01|          9|Staten Island|                1|   22000.0|2.632|    965.6|   20.6|   15.0|   1017.6|             200|\n",
      "| 2023-07-01|         10|        Bronx|               11|   22000.0|2.632|    965.6|   21.1|   16.1|   1017.8|             415|\n",
      "| 2023-07-01|         10|     Brooklyn|               11|   22000.0|2.632|    965.6|   21.1|   16.1|   1017.8|             571|\n",
      "| 2023-07-01|         10|       Queens|              267|   22000.0|2.632|    965.6|   21.1|   16.1|   1017.8|             472|\n",
      "| 2023-07-01|         10|    Manhattan|             2651|   22000.0|2.632|    965.6|   21.1|   16.1|   1017.8|             980|\n",
      "| 2023-07-01|         11|     Brooklyn|               16|   22000.0|2.632|   1126.5|   23.3|   15.6|   1018.0|             307|\n",
      "+-----------+-----------+-------------+-----------------+----------+-----+---------+-------+-------+---------+----------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show 10 rows of the merged2 data\n",
    "merged2.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-----------------+-------------------------+-----------+-----------+-----------+-----------+-----------+-----------+------------------------+\n",
      "|pickup_date_missing|pickup_hour_missing|PUBorough_missing|hourly_trip_count_missing|CIG_missing|WND_missing|VIS_missing|TMP_missing|DEW_missing|SLP_missing|Number of Events_missing|\n",
      "+-------------------+-------------------+-----------------+-------------------------+-----------+-----------+-----------+-----------+-----------+-----------+------------------------+\n",
      "|                0.0|                0.0|              0.0|                      0.0|        0.0|        0.0|        0.0|        0.0|        0.0|        0.0|                     0.0|\n",
      "+-------------------+-------------------+-----------------+-------------------------+-----------+-----------+-----------+-----------+-----------+-----------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check missing values in merged2\n",
    "merged2.agg(*[\n",
    "    (1 - (F.count(c) / F.count('*'))).alias(c + '_missing')\n",
    "    for c in merged2.columns\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23635"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the number of rows in the merged2 data\n",
    "merged2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- pickup_date: date (nullable = true)\n",
      " |-- pickup_hour: integer (nullable = true)\n",
      " |-- PUBorough: string (nullable = true)\n",
      " |-- hourly_trip_count: long (nullable = false)\n",
      " |-- CIG: double (nullable = false)\n",
      " |-- WND: double (nullable = false)\n",
      " |-- VIS: double (nullable = false)\n",
      " |-- TMP: double (nullable = false)\n",
      " |-- DEW: double (nullable = false)\n",
      " |-- SLP: double (nullable = false)\n",
      " |-- Number of Events: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check schema\n",
    "merged2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export for EDA_1 and model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the merged data and overwrite\n",
    "merged2.write.mode(\"overwrite\").parquet(\"../data/curated/merged_data/first_cleaned.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
