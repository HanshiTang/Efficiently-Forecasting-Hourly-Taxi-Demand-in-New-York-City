{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing_final\n",
    "This notebook aggregates 3 preprocessed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sbs\n",
    "import geopandas as gpd\n",
    "import folium "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a spark session with increased memory allocation\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"ADS Project1\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.driver.memory\", \"8g\")  # Set the driver memory to 8GB\n",
    "    .config(\"spark.executor.memory\", \"8g\")  # Set the executor memory to 8GB\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.parquet.compression.codec\",\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data from preprocessed tlc data\n",
    "tdf = spark.read.parquet(\"../data/raw/tlc_df.parquet\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the preprocessed weather data\n",
    "wdf = spark.read.csv(\"../data/raw/NYC_weather_raw.csv\", header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the preprocessed event data\n",
    "edf = spark.read.parquet(\"../data/raw/NYC_Permitted_Event_Information_Historical.parquet\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+---------+-------------+-----------+------------+-----------+------------+\n",
      "|VendorID|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|ehail_fee|trip_duration|pickup_hour|dropoff_hour|pickup_date|dropoff_date|\n",
      "+--------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+---------+-------------+-----------+------------+-----------+------------+\n",
      "|       2|              1|         1.75|         1|             false|          68|          50|           2|       12.1|  1.0|    0.5|       0.0|         0.0|                  1.0|        17.1|                 2.5|      0.0|         10.0|          0|           0| 2023-12-01|  2023-12-01|\n",
      "|       1|              1|          3.6|         1|             false|          48|          43|           1|       17.7|  3.5|    0.5|      4.55|         0.0|                  1.0|       27.25|                 2.5|      0.0|         16.0|          0|           0| 2023-12-01|  2023-12-01|\n",
      "|       2|              1|        10.28|         1|             false|         170|          95|           1|       44.3|  1.0|    0.5|     11.25|        6.94|                  1.0|       67.49|                 2.5|      0.0|         29.0|          0|           0| 2023-12-01|  2023-12-01|\n",
      "|       2|              1|         2.66|         1|             false|         163|         158|           1|       14.9|  1.0|    0.5|      3.98|         0.0|                  1.0|       23.88|                 2.5|      0.0|         14.0|          0|           0| 2023-12-01|  2023-12-01|\n",
      "|       2|              1|        15.43|         1|             false|         132|         150|           2|       59.0|  1.0|    0.5|       0.0|         0.0|                  1.0|       63.25|                 0.0|      0.0|         24.0|          0|           0| 2023-12-01|  2023-12-01|\n",
      "+--------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+---------+-------------+-----------+------------+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show 5 rows of the tlc data\n",
    "tdf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- passenger_count: long (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: long (nullable = true)\n",
      " |-- store_and_fwd_flag: boolean (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- ehail_fee: double (nullable = true)\n",
      " |-- trip_duration: double (nullable = true)\n",
      " |-- pickup_hour: integer (nullable = true)\n",
      " |-- dropoff_hour: integer (nullable = true)\n",
      " |-- pickup_date: date (nullable = true)\n",
      " |-- dropoff_date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# schema of the tlc data\n",
    "tdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+-------+---+------+---+----+------+\n",
      "|      DATE|HOUR|    CIG|WND|   VIS|TMP| DEW|   SLP|\n",
      "+----------+----+-------+---+------+---+----+------+\n",
      "|2023-12-01|   0|22000.0|4.1|1609.3|9.4|-2.8|1020.1|\n",
      "|2023-12-01|   1|22000.0|2.1|1609.3|8.9|-2.2|1020.0|\n",
      "|2023-12-01|   2|22000.0|3.1|1609.3|8.9|-2.2|1020.4|\n",
      "|2023-12-01|   3|22000.0|3.1|1609.3|8.3|-1.7|1020.7|\n",
      "|2023-12-01|   4|22000.0|3.1|1609.3|7.8|-1.7|1020.8|\n",
      "+----------+----+-------+---+------+---+----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show 5 rows of the weather data\n",
    "wdf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+----------+----------+--------+-------------+-------------+--------------------+\n",
      "|Event ID|Start Date|Start Hour|  End Date|End Hour|   Event Type|Event Borough|      Event Location|\n",
      "+--------+----------+----------+----------+--------+-------------+-------------+--------------------+\n",
      "|  684438|2023-12-09|         7|2023-12-09|      10|Special Event|     Brooklyn|Prospect Park: Pi...|\n",
      "|  693693|2023-12-03|        12|2023-12-03|      14|Special Event|    Manhattan|Central Park: Wag...|\n",
      "|  686564|2023-12-03|        17|2023-12-03|      18|Special Event|    Manhattan|Carl Schurz Park:...|\n",
      "|  684416|2023-12-09|         9|2023-12-09|      11|Special Event|    Manhattan|Washington Square...|\n",
      "|  687023|2023-12-01|        11|2023-12-01|      12|Special Event|    Manhattan|Central Park: Lad...|\n",
      "+--------+----------+----------+----------+--------+-------------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show 5 rows of the event data\n",
    "edf.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tlc aggregation for number of trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert pickup_date and pickup_hour to a timestamp and create Time column\n",
    "tdf = tdf.withColumn(\n",
    "    'Time', \n",
    "    to_timestamp(concat_ws(' ', col('pickup_date'), col('pickup_hour')))\n",
    ")\n",
    "\n",
    "# Aggregate hourly trip counts\n",
    "hourly_trip_counts = tdf.groupBy('Time').agg(count('*').alias('hourly_trip_count'))\n",
    "\n",
    "# Aggregate daily trip counts\n",
    "daily_trip_counts = tdf.groupBy('pickup_date').agg(count('*').alias('daily_trip_count'))\n",
    "\n",
    "# drop the Time column\n",
    "tdf = tdf.drop('Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+---------+-------------+-----------+------------+-----------+------------+\n",
      "|VendorID|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|ehail_fee|trip_duration|pickup_hour|dropoff_hour|pickup_date|dropoff_date|\n",
      "+--------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+---------+-------------+-----------+------------+-----------+------------+\n",
      "|       2|              1|         1.75|         1|             false|          68|          50|           2|       12.1|  1.0|    0.5|       0.0|         0.0|                  1.0|        17.1|                 2.5|      0.0|         10.0|          0|           0| 2023-12-01|  2023-12-01|\n",
      "|       1|              1|          3.6|         1|             false|          48|          43|           1|       17.7|  3.5|    0.5|      4.55|         0.0|                  1.0|       27.25|                 2.5|      0.0|         16.0|          0|           0| 2023-12-01|  2023-12-01|\n",
      "|       2|              1|        10.28|         1|             false|         170|          95|           1|       44.3|  1.0|    0.5|     11.25|        6.94|                  1.0|       67.49|                 2.5|      0.0|         29.0|          0|           0| 2023-12-01|  2023-12-01|\n",
      "|       2|              1|         2.66|         1|             false|         163|         158|           1|       14.9|  1.0|    0.5|      3.98|         0.0|                  1.0|       23.88|                 2.5|      0.0|         14.0|          0|           0| 2023-12-01|  2023-12-01|\n",
      "|       2|              1|        15.43|         1|             false|         132|         150|           2|       59.0|  1.0|    0.5|       0.0|         0.0|                  1.0|       63.25|                 0.0|      0.0|         24.0|          0|           0| 2023-12-01|  2023-12-01|\n",
      "+--------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+---------+-------------+-----------+------------+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tdf.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map taxi zones to boroughs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------+--------------------+----------------+--------------------+----------+-------------+\n",
      "|OBJECTID|     Shape_Leng|            the_geom|      Shape_Area|                zone|LocationID|      borough|\n",
      "+--------+---------------+--------------------+----------------+--------------------+----------+-------------+\n",
      "|       1| 0.116357453189|MULTIPOLYGON (((-...|  7.823067885E-4|      Newark Airport|         1|          EWR|\n",
      "|       2|  0.43346966679|MULTIPOLYGON (((-...|0.00486634037837|         Jamaica Bay|         2|       Queens|\n",
      "|       3|0.0843411059012|MULTIPOLYGON (((-...|3.14414156821E-4|Allerton/Pelham G...|         3|        Bronx|\n",
      "|       4|0.0435665270921|MULTIPOLYGON (((-...|1.11871946192E-4|       Alphabet City|         4|    Manhattan|\n",
      "|       5|0.0921464898574|MULTIPOLYGON (((-...|4.97957489363E-4|       Arden Heights|         5|Staten Island|\n",
      "+--------+---------------+--------------------+----------------+--------------------+----------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the zones DataFrame\n",
    "zones = spark.read.csv(\"../data/landing/external/taxi_zones.csv\", header=True, inferSchema=True)\n",
    "# show 5 rows of the zones data\n",
    "zones.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the tdf DataFrame with zones to get the borough for PULocationID\n",
    "tdf = tdf.join(zones.select('LocationID', 'borough').withColumnRenamed('borough', 'PUBorough'),\n",
    "               tdf['PULocationID'] == zones['LocationID'], 'left').drop('LocationID')\n",
    "\n",
    "# Join the tdf DataFrame with zones to get the borough for DOLocationID\n",
    "tdf = tdf.join(zones.select('LocationID', 'borough').withColumnRenamed('borough', 'DOBorough'),\n",
    "               tdf['DOLocationID'] == zones['LocationID'], 'left').drop('LocationID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+---------+-------------+-----------+------------+-----------+------------+---------+---------+\n",
      "|VendorID|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|ehail_fee|trip_duration|pickup_hour|dropoff_hour|pickup_date|dropoff_date|PUBorough|DOBorough|\n",
      "+--------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+---------+-------------+-----------+------------+-----------+------------+---------+---------+\n",
      "|       2|              1|         1.75|         1|             false|          68|          50|           2|       12.1|  1.0|    0.5|       0.0|         0.0|                  1.0|        17.1|                 2.5|      0.0|         10.0|          0|           0| 2023-12-01|  2023-12-01|Manhattan|Manhattan|\n",
      "|       1|              1|          3.6|         1|             false|          48|          43|           1|       17.7|  3.5|    0.5|      4.55|         0.0|                  1.0|       27.25|                 2.5|      0.0|         16.0|          0|           0| 2023-12-01|  2023-12-01|Manhattan|Manhattan|\n",
      "|       2|              1|        10.28|         1|             false|         170|          95|           1|       44.3|  1.0|    0.5|     11.25|        6.94|                  1.0|       67.49|                 2.5|      0.0|         29.0|          0|           0| 2023-12-01|  2023-12-01|Manhattan|   Queens|\n",
      "|       2|              1|         2.66|         1|             false|         163|         158|           1|       14.9|  1.0|    0.5|      3.98|         0.0|                  1.0|       23.88|                 2.5|      0.0|         14.0|          0|           0| 2023-12-01|  2023-12-01|Manhattan|Manhattan|\n",
      "|       2|              1|        15.43|         1|             false|         132|         150|           2|       59.0|  1.0|    0.5|       0.0|         0.0|                  1.0|       63.25|                 0.0|      0.0|         24.0|          0|           0| 2023-12-01|  2023-12-01|   Queens| Brooklyn|\n",
      "+--------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+---------+-------------+-----------+------------+-----------+------------+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tdf.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation of number of events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-------------+----------------+\n",
      "|Start Date|Start Hour|Event Borough|Number of Events|\n",
      "+----------+----------+-------------+----------------+\n",
      "|2023-12-01|         0|    Manhattan|              36|\n",
      "|2023-12-01|         1|     Brooklyn|               1|\n",
      "|2023-12-01|         7|    Manhattan|               2|\n",
      "|2023-12-01|         7|       Queens|               1|\n",
      "|2023-12-01|         8|        Bronx|               7|\n",
      "|2023-12-01|         8|     Brooklyn|              10|\n",
      "|2023-12-01|         8|    Manhattan|              12|\n",
      "|2023-12-01|         8|       Queens|               6|\n",
      "|2023-12-01|         8|Staten Island|               1|\n",
      "|2023-12-01|         9|        Bronx|               2|\n",
      "|2023-12-01|         9|     Brooklyn|               4|\n",
      "|2023-12-01|         9|    Manhattan|               5|\n",
      "|2023-12-01|         9|       Queens|               3|\n",
      "|2023-12-01|         9|Staten Island|               4|\n",
      "|2023-12-01|        10|        Bronx|               2|\n",
      "|2023-12-01|        10|     Brooklyn|               3|\n",
      "|2023-12-01|        10|    Manhattan|               4|\n",
      "|2023-12-01|        10|       Queens|               5|\n",
      "|2023-12-01|        11|     Brooklyn|               1|\n",
      "|2023-12-01|        11|    Manhattan|               6|\n",
      "+----------+----------+-------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combine 'Start Date' and 'Start Hour' to create a 'Start Time' column (formatted correctly)\n",
    "edf = edf.withColumn('Start Time', concat_ws(' ', col('Start Date'), col('Start Hour')))\n",
    "\n",
    "# Aggregate the number of events per date, hour, and borough\n",
    "edf = edf.groupBy('Start Date', 'Start Hour', 'Event Borough').agg(count('Event ID').alias('Number of Events'))\n",
    "\n",
    "# Sort the results if needed\n",
    "edf = edf.orderBy('Start Date', 'Start Hour', 'Event Borough')\n",
    "\n",
    "# Show or save the aggregated results\n",
    "edf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create unified datetime columns in each dataset\n",
    "\n",
    "# For tdf (taxi dataset)\n",
    "tdf = tdf.withColumn(\"datetime\", to_timestamp(concat_ws(\" \", col(\"pickup_date\"), col(\"pickup_hour\")), \"yyyy-MM-dd H\"))\n",
    "\n",
    "# For edf (event dataset)\n",
    "edf = edf.withColumn(\"datetime\", to_timestamp(concat_ws(\" \", col(\"Start Date\"), col(\"Start Hour\")), \"yyyy-MM-dd H\"))\n",
    "\n",
    "# For wdf (weather dataset)\n",
    "wdf = wdf.withColumn(\"datetime\", to_timestamp(concat_ws(\" \", col(\"DATE\"), col(\"HOUR\")), \"yyyy-MM-dd H\"))\n",
    "\n",
    "# Step 2: Join tdf (taxi dataset) with edf (event dataset) on datetime and borough\n",
    "tdf_edf = tdf.join(edf, \n",
    "                   (tdf[\"datetime\"] == edf[\"datetime\"]) & \n",
    "                   (tdf[\"PUBorough\"] == edf[\"Event Borough\"]), \n",
    "                   \"left\")\n",
    "\n",
    "# Drop the redundant datetime column from edf after the join to avoid ambiguity\n",
    "tdf_edf = tdf_edf.drop(edf[\"datetime\"])\n",
    "\n",
    "# Step 3: Join the result with the weather dataset on datetime only (since weather data is from one station)\n",
    "final_df = tdf_edf.join(wdf, \n",
    "                        tdf_edf[\"datetime\"] == wdf[\"datetime\"], \n",
    "                        \"left\")\n",
    "\n",
    "# Step 4: Drop the redundant datetime columns after the final join\n",
    "final_df = final_df.drop(wdf[\"datetime\"]).drop(edf[\"datetime\"]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the redundant datetime columns after the final join \n",
    "final_df = final_df.drop(\"weather_datetime\", 'event_datetime', 'datetime', 'DATE', 'HOUR', 'Start Date', 'Start Hour', 'Event Borough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.select(\n",
    "    \"pickup_date\", \"pickup_hour\", \"dropoff_date\", \"dropoff_hour\",  # Date and Time Columns\n",
    "    \"VendorID\", \"passenger_count\", \"trip_distance\", \"RatecodeID\",  # Trip Information\n",
    "    \"PULocationID\", \"PUBorough\", \"DOLocationID\", \"DOBorough\",      # Location Information\n",
    "    \"payment_type\", \"fare_amount\", \"extra\", \"mta_tax\", \"tip_amount\", \"tolls_amount\", \"improvement_surcharge\",  # Payment Details\n",
    "    \"congestion_surcharge\", \"total_amount\", \"ehail_fee\",            # Additional Charges\n",
    "    \"trip_duration\",                                                 # Duration\n",
    "    \"Number of Events\",                                              # Event Data\n",
    "    \"CIG\", \"WND\", \"VIS\", \"TMP\", \"DEW\", \"SLP\"                        # Weather Data\n",
    ") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling missing data\n",
    "The assumption is no events occured if number of evnets in Null\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values in Number of Events column with 0\n",
    "final_df = final_df.fillna(0, subset=['Number of Events'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mode for PUBorough based on PULocationID\n",
    "puborough_mode = final_df.groupBy(\"PULocationID\", \"PUBorough\").agg(count(\"*\").alias(\"count\"))\n",
    "puborough_mode = puborough_mode.withColumn(\"row\", row_number().over(Window.partitionBy(\"PULocationID\").orderBy(col(\"count\").desc())))\n",
    "puborough_mode = puborough_mode.filter(col(\"row\") == 1).select(\"PULocationID\", col(\"PUBorough\").alias(\"PUBorough_mode\"))\n",
    "\n",
    "# Join to fill in missing PUBorough\n",
    "final_df = final_df.join(puborough_mode, \"PULocationID\", \"left\").withColumn(\n",
    "    \"PUBorough\", coalesce(col(\"PUBorough\"), col(\"PUBorough_mode\"))\n",
    ").drop(\"PUBorough_mode\")\n",
    "\n",
    "# Calculate the mode for DOBorough based on DOLocationID\n",
    "doborough_mode = final_df.groupBy(\"DOLocationID\", \"DOBorough\").agg(count(\"*\").alias(\"count\"))\n",
    "doborough_mode = doborough_mode.withColumn(\"row\", row_number().over(Window.partitionBy(\"DOLocationID\").orderBy(col(\"count\").desc())))\n",
    "doborough_mode = doborough_mode.filter(col(\"row\") == 1).select(\"DOLocationID\", col(\"DOBorough\").alias(\"DOBorough_mode\"))\n",
    "\n",
    "# Join to fill in missing DOBorough\n",
    "final_df = final_df.join(doborough_mode, \"DOLocationID\", \"left\").withColumn(\n",
    "    \"DOBorough\", coalesce(col(\"DOBorough\"), col(\"DOBorough_mode\"))\n",
    ").drop(\"DOBorough_mode\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a window specification to forward fill missing values\n",
    "window_spec = Window.partitionBy().orderBy(\"pickup_date\", \"pickup_hour\").rowsBetween(-sys.maxsize, 0)\n",
    "\n",
    "# Apply forward fill to the missing weather columns\n",
    "final_df = final_df.withColumn(\"CIG\", last(col(\"CIG\"), ignorenulls=True).over(window_spec))\n",
    "final_df = final_df.withColumn(\"WND\", last(col(\"WND\"), ignorenulls=True).over(window_spec))\n",
    "final_df = final_df.withColumn(\"VIS\", last(col(\"VIS\"), ignorenulls=True).over(window_spec))\n",
    "final_df = final_df.withColumn(\"TMP\", last(col(\"TMP\"), ignorenulls=True).over(window_spec))\n",
    "final_df = final_df.withColumn(\"DEW\", last(col(\"DEW\"), ignorenulls=True).over(window_spec))\n",
    "final_df = final_df.withColumn(\"SLP\", last(col(\"SLP\"), ignorenulls=True).over(window_spec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep rows within the date range of the taxi data\n",
    "final_df = final_df.filter(col(\"pickup_date\").between(\"2023-12-01\", \"2024-5-31\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/28 03:38:17 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:38:17 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:38:17 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:38:17 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:38:17 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:38:17 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:38:17 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:38:18 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:38:18 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:38:18 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:38:18 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:38:18 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:38:18 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:38:18 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:38:18 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:38:18 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:38:18 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:38:18 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:38:18 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "ERROR:root:KeyboardInterrupt while sending command.][Stage 253:>  (0 + 0) / 8]8]\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/socket.py\", line 707, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# show 5 rows of the final data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mfinal_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pyspark/sql/dataframe.py:945\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow\u001b[39m(\u001b[38;5;28mself\u001b[39m, n: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, truncate: Union[\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, vertical: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    886\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Prints the first ``n`` rows to the console.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \n\u001b[1;32m    888\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;124;03m    name | Bob\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 945\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_show_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pyspark/sql/dataframe.py:963\u001b[0m, in \u001b[0;36mDataFrame._show_string\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m    958\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_BOOL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    959\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(vertical)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[1;32m    960\u001b[0m     )\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncate, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m truncate:\n\u001b[0;32m--> 963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1314\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/socket.py:707\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 707\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    709\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# show 5 rows of the final data\n",
    "final_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export file to curated folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/28 03:33:55 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:33:55 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:33:55 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:33:55 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:33:55 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:33:55 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:33:55 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:33:56 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:33:56 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:33:56 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:33:56 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:33:56 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:33:56 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:33:56 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:33:56 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:33:56 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:33:56 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:33:56 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:33:56 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:34:39 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:34:39 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:35:12 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:35:12 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:35:12 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:35:12 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:35:29 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:35:29 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:35:29 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:35:29 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:35:29 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:35:29 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:35:29 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:35:29 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:35:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:35:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:35:51 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:35:51 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:35:56 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:35:56 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:35:56 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:35:56 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:35:56 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:35:56 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:36:15 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/08/28 03:36:15 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# save the merged data\n",
    "final_df.write.parquet(\"../data/curated/tlc_data/first_cleaned.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
